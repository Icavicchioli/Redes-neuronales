{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79d44e76",
   "metadata": {},
   "source": [
    "# Redes Neuronales - TP1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9903c47",
   "metadata": {},
   "source": [
    "## Ej 2\n",
    "\n",
    "1. Comprobar estadísticamente la capacidad de la red de Hopfield ‘82 calculando la cantidad máxima de patrones pseudo-aleatorios aprendidos en función del tamaño de la red. Obtener experimentalmente los resultados de la siguiente tabla (los valores de la tabla corresponden a una iteración con actualización sincrónica).\n",
    "\n",
    "|$P_{error}$|${p_{max}}/{N}$|\n",
    "|-|-|\n",
    "|0.001|0.105|\n",
    "|0.0036|0.138|\n",
    "|0.01|0.185|\n",
    "|0.05|0.37|\n",
    "|0.1|0.61|\n",
    "\n",
    "2. Proponga una manera de generar patrones con distintos grados de correlación.\n",
    "Utilice el método propuesto para analizar cómo varía la capacidad de la red de\n",
    "Hopfield en función de la correlación entre patrones.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e018a9a1",
   "metadata": {},
   "source": [
    "Mi idea es crear una función o clase que reciba un set de probabilidades de error y un tamaño de red particular, y devuelva la capacidad para cada umbral de error. \n",
    "\n",
    "En lo que respecta a patrones, siempre se va a evaluar con patrones con una correlación determinada. un método los va a generar aleatoriamente, otro debería poder hacerlos con una correlación \"custom\". \n",
    "\n",
    "\n",
    "Una aclaración importante: el primer inciso va a parecer desprolijo en comparación con este, pero es porque en ese prioricé tener algo funcionando. Ahora que entendí un poco más es más fácil colocar todo en una clase y operar desde ahí. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "827872b2",
   "metadata": {},
   "source": [
    "Para el inciso que genera vectores correlacionados se hace lo siguiente. Se suponen vectores X e Y generados de tal forma que toman valores discretos $-1$ y $1$ con probabilidad $1/2$. Así, sus medias son cero y las varianzas son unitarias. Se plantea el coeficiente de correlación de pearson como:\n",
    "\n",
    "$$\n",
    "corr_{coef} = \\frac{cov(X,Y)}{\\sqrt{Var(X)\\cdot Var(Y)}} =  E[X \\cdot Y] - E[X]E[Y] = E[X \\cdot Y]\n",
    "$$\n",
    "\n",
    "Y ahora $E[X \\cdot Y]$ se abre por esperanza total en:\n",
    "\n",
    "$$\n",
    "E[X \\cdot Y] = P(X=1)P(Y=1)(1)(1) * P(X=1)P(Y=-1)(1)(-1) * P(X=-1)P(Y=1)(-1)(1) * P(X=-1)P(Y=-1)(-1)(-1)\n",
    "$$\n",
    "\n",
    "Denomino $p = P(X=Y)$ la probabilidad de que los vectores concuerden en algún bit. \n",
    "\n",
    "$$\n",
    "E[X \\cdot Y] = p - (1-p) = 2p-1\n",
    "$$\n",
    "\n",
    "Entonces:\n",
    "$$\n",
    "corr_{coef} = 2p-1 \\Leftrightarrow p = \\frac{corr_{coef} +1}{2}\n",
    "$$\n",
    "\n",
    "De esta manera se puede tomar un vector X generado como se generaría cualquier vector aleatorio y luego se genera un Y en base a la probabilidad de que concuerde con el X. Si $x=1$ se tira una moneda de probabilidad p de que $y=x$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41967781",
   "metadata": {},
   "outputs": [],
   "source": [
    "# primero importamos numpy y algo para leer imágenes y hacer graficos\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8d75b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class evaluacion_capacidad_red_neuronal:\n",
    "    def __init__(self, cantidad_neuronas):\n",
    "        self.N = cantidad_neuronas\n",
    "        self.W = None\n",
    "\n",
    "    def evaluar(self, datos_prueba):\n",
    "        # Lógica para evaluar la capacidad del modelo\n",
    "        pass\n",
    "\n",
    "    def estado_aleatorio(self,correlacion):\n",
    "        \"\"\"permite generar estados para entrenar una red. devuelve una matriz lista para ser usada para calcular W\"\"\"\n",
    "\n",
    "        N =self.N # cantidad de neuronas\n",
    "\n",
    "        rng = np.random.default_rng() # generador de números aleatorios 0 o 1\n",
    "        vector = np.asarray(rng.integers(2, size=N)).reshape(-1, 1) # generamos 1 tirada de cierto tamaño\n",
    "\n",
    "        vector = (vector.reshape(-1, 1))# Convertir a columna\n",
    "\n",
    "        return vector *2 -1 # de -1 a 1\n",
    "    \n",
    "\n",
    "    def calcular_W(self, patrones, eta = 1):\n",
    "        \"\"\"\n",
    "        Para calcular la W correspondiente a los patrones recibidos. Se asume que el formato es el que siempre se viene trabajando de vectores colmunas\n",
    "        Se supone un \"eta\" unitario por comodidad. \n",
    "        \"\"\"\n",
    "\n",
    "        n_neuronas = self.N\n",
    "        n_patrones = patrones.shape[1]\n",
    "\n",
    "        X = patrones\n",
    "\n",
    "        W = (X @ X.T - n_patrones*np.eye(n_neuronas)) * eta\n",
    "\n",
    "        self.W = W\n",
    "\n",
    "        return\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    def step_red_neuronal(self, patron_inicial):\n",
    "        \"\"\"\n",
    "        Patrón inicial debe ser vector columna.\n",
    "        \"\"\"\n",
    "        estado = np.copy(patron_inicial)\n",
    "        estado = self.W @ estado\n",
    "        estado = np.sign(estado)\n",
    "        estado = np.where(estado == 0, 1, estado)  # Manejar ceros\n",
    "        return estado\n",
    "        \n",
    "\n",
    "    def agregar_columna(self, datos,correlacion):\n",
    "        \"\"\"Esto lo uso para agregar de a 1 patron a la vez y no tener que hacer muchos randoms\"\"\"\n",
    "        rnd = self.estado_aleatorio(correlacion=correlacion)\n",
    "        datos = np.hstack((datos, rnd))\n",
    "        return datos,rnd # debería ser cómodo para cuando itere para encontrar cuando fallan las cosas\n",
    "    \n",
    "    def comprobar_memoria(self, original):\n",
    "        salida = self.step_red_neuronal(original)\n",
    "        cant_bits_erroneos = np.sum(np.abs(original-salida)/2) # si hago la diferencia y divido por 2 debería obtener \n",
    "        # la cantidad de bits diferentes porque 1+1 = 2 ,1-1 = 0 ,-1-1 = -2\n",
    "        return cant_bits_erroneos\n",
    "    \n",
    "    def actualizar_W(self, nuevo_patron, eta=1):\n",
    "        \"\"\"\n",
    "        Actualiza la matriz de pesos de una red de Hopfield con un nuevo patrón. para optimizar un poco\n",
    "        \n",
    "        Parámetros\n",
    "        ----------\n",
    "        W_vieja : np.ndarray\n",
    "            Matriz de pesos ya entrenada (N x N).\n",
    "        nuevo_patron : np.ndarray\n",
    "            Patrón nuevo en forma de vector columna (N x 1), con valores en {-1, +1}.\n",
    "        eta : float\n",
    "            Factor de aprendizaje (default=1).\n",
    "            \n",
    "        Retorna\n",
    "        -------\n",
    "        np.ndarray\n",
    "            Nueva matriz de pesos W actualizada.\n",
    "        \"\"\"\n",
    "        W_vieja = self.W\n",
    "        n_neuronas = W_vieja.shape[0]\n",
    "        x = nuevo_patron.reshape((n_neuronas, 1))\n",
    "\n",
    "        # Hebb incremental con eliminación de autoconexiones\n",
    "        W_nueva = W_vieja + eta * (x @ x.T - np.eye(n_neuronas))\n",
    "\n",
    "        self.W = W_nueva\n",
    "        return\n",
    "\n",
    "    def estimar_errores_vs_patrones(self, max_patron = -1, correlacion = 0):\n",
    "        if correlacion == 0:\n",
    "            lista_errores,lista_cant_patrones = _estimar_errores_vs_patrones_descorr(max_patron)\n",
    "        else:\n",
    "            lista_errores,lista_cant_patrones = _estimar_errores_vs_patrones_correlacionados(max_patron,correlacion)\n",
    "\n",
    "\n",
    "\n",
    "        return lista_errores,lista_cant_patrones\n",
    "    \n",
    "\n",
    "    def _estimar_errores_vs_patrones_correlacionados(self, max_patron = -1, correlacion):\n",
    "        if max_patron == -1:\n",
    "            max_patron = self.N\n",
    "\n",
    "        lista_cant_patrones = []\n",
    "        lista_errores = []\n",
    "\n",
    "        for i in range(max_patron):\n",
    "            if i == 0: \n",
    "                datos = self.estado_aleatorio()\n",
    "                self.calcular_W(datos) # la mete en el self\n",
    "            else:\n",
    "                datos,rnd = self.agregar_columna(datos) # rnd es el nuevo estado\n",
    "                self.actualizar_W(rnd)\n",
    "\n",
    "\n",
    "            # acá tenemos una matriz que va a ir aumentando en cantidad de patrones con las iteraciones\n",
    "            # ahora invoco el cálculo de W\n",
    "            \n",
    "\n",
    "            # ahora lo que quiero es iterar por la cantidad de patrones en i y sumar la cantidad de errores\n",
    "            errores_totales_bits = 0\n",
    "            for k in range(i):\n",
    "                estado_original_actual = datos[:,k] # el patrón k-ésimo\n",
    "                error_actual = self.comprobar_memoria(estado_original_actual) # vamos a ir sumando\n",
    "                error_actual = error_actual/(self.N * (i+1))\n",
    "                errores_totales_bits = errores_totales_bits+error_actual\n",
    "\n",
    "            lista_errores.append(errores_totales_bits)\n",
    "            lista_cant_patrones.append(i+1)\n",
    "\n",
    "        return lista_errores,lista_cant_patrones\n",
    "    \n",
    "\n",
    "    def _estimar_errores_vs_patrones_descorr(self, max_patron = -1):\n",
    "        if max_patron == -1:\n",
    "            max_patron = self.N\n",
    "\n",
    "        lista_cant_patrones = []\n",
    "        lista_errores = []\n",
    "\n",
    "        for i in range(max_patron):\n",
    "            if i == 0: \n",
    "                datos = self.estado_aleatorio()\n",
    "                self.calcular_W(datos) # la mete en el self\n",
    "            else:\n",
    "                datos,rnd = self.agregar_columna(datos) # rnd es el nuevo estado\n",
    "                self.actualizar_W(rnd)\n",
    "\n",
    "\n",
    "            # acá tenemos una matriz que va a ir aumentando en cantidad de patrones con las iteraciones\n",
    "            # ahora invoco el cálculo de W\n",
    "            \n",
    "\n",
    "            # ahora lo que quiero es iterar por la cantidad de patrones en i y sumar la cantidad de errores\n",
    "            errores_totales_bits = 0\n",
    "            for k in range(i):\n",
    "                estado_original_actual = datos[:,k] # el patrón k-ésimo\n",
    "                error_actual = self.comprobar_memoria(estado_original_actual) # vamos a ir sumando\n",
    "                error_actual = error_actual/(self.N * (i+1))\n",
    "                errores_totales_bits = errores_totales_bits+error_actual\n",
    "\n",
    "            lista_errores.append(errores_totales_bits)\n",
    "            lista_cant_patrones.append(i+1)\n",
    "\n",
    "        return lista_errores,lista_cant_patrones\n",
    "    \n",
    "\n",
    "    def capacidad_dada_proba(lista_errores, lista_cant_patrones, prob_error_max):\n",
    "        \"\"\"\n",
    "        Dada una curva de errores vs patrones, devuelve la máxima cantidad \n",
    "        de patrones que se pueden almacenar sin superar un error dado.\n",
    "        \n",
    "        Parámetros\n",
    "        ----------\n",
    "        lista_errores : list[float]\n",
    "            Lista de probabilidades de error acumuladas (salida de estimar_errores_vs_patrones).\n",
    "        lista_cant_patrones : list[int]\n",
    "            Lista con la cantidad de patrones correspondientes.\n",
    "        prob_error_max : float\n",
    "            Probabilidad máxima de error permitida (ej: 0.05).\n",
    "            \n",
    "        Retorna\n",
    "        -------\n",
    "        int\n",
    "            Cantidad máxima de patrones que cumple la condición.\n",
    "        \"\"\"\n",
    "        capacidad = 0\n",
    "        for err, cant in zip(lista_errores, lista_cant_patrones):\n",
    "            if err <= prob_error_max:\n",
    "                capacidad = cant\n",
    "            else:\n",
    "                break\n",
    "        return capacidad\n",
    "    \n",
    "\n",
    "    def generar_patrones_correlacionados(self, cantidad, correlacion):\n",
    "        \"\"\"\n",
    "        Genera 'cantidad' patrones binarios (-1,1) con una correlación aproximada 'correlacion' respecto a un patrón base.\n",
    "        correlacion: valor entre 0 (totalmente aleatorio) y 1 (idéntico al patrón base).\n",
    "        \"\"\"\n",
    "        N = self.N\n",
    "        rng = np.random.default_rng()\n",
    "        patron_base = rng.choice([-1, 1], size=(N, 1))\n",
    "        patrones = [patron_base]\n",
    "        p = (1 - correlacion) / 2\n",
    "        for _ in range(cantidad - 1):\n",
    "            ruido = rng.random((N, 1)) < p\n",
    "            nuevo_patron = np.where(ruido, -patron_base, patron_base)\n",
    "            patrones.append(nuevo_patron)\n",
    "        return np.hstack(patrones)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2392b52e",
   "metadata": {},
   "source": [
    "para la primer prueba voy a probar con 1000 neuronas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86d44797",
   "metadata": {},
   "outputs": [],
   "source": [
    "ERN = evaluacion_capacidad_red_neuronal(100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d1ff988",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iters = 100\n",
    "errores, n_patrones = ERN.estimar_errores_vs_patrones()\n",
    "errores = np.array(errores)\n",
    "for _ in range(n_iters-1):\n",
    "    err2,_ = ERN.estimar_errores_vs_patrones()\n",
    "    errores += np.array(err2)\n",
    "errores = errores / 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "369fd4f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Para el umbral 0.001 se estima una capacidad de 0.200\n",
      "\n",
      "Para el umbral 0.0036 se estima una capacidad de 0.260\n",
      "\n",
      "Para el umbral 0.01 se estima una capacidad de 0.320\n",
      "\n",
      "Para el umbral 0.05 se estima una capacidad de 0.540\n",
      "\n",
      "Para el umbral 0.1 se estima una capacidad de 0.760\n",
      "\n"
     ]
    }
   ],
   "source": [
    "umbrales =  [0.001,0.0036,0.01,0.05,0.1]\n",
    "n_neuronas = 50\n",
    "for umbral in umbrales:\n",
    "    cap = evaluacion_capacidad_red_neuronal.capacidad_dada_proba(errores, n_patrones, umbral)\n",
    "    print(f\"Para el umbral {umbral} se estima una capacidad de {cap/n_neuronas:.3f}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
