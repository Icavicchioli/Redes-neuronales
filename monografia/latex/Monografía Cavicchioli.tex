% !TEX TS-program = pdflatex
% !TEX encoding = UTF-8 Unicode

% This is a simple template for a LaTeX document using the ``article'' class.
% See ``book'', ``report'', ``letter'' for other types of document.

\documentclass[11pt]{article} % use larger type; default would be 10pt

\usepackage[utf8]{inputenc} % set input encoding (not needed with XeLaTeX)

%%% Examples of Article customizations
% These packages are optional, depending whether you want the features they provide.
% See the LaTeX Companion or other references for full information.

%%% PAGE DIMENSIONS
\usepackage{geometry} % to change the page dimensions
\geometry{a4paper} % or letterpaper (US) or a5paper or....
\geometry{margin=1in} % for example, change the margins to 2 inches all round
% \geometry{landscape} % set up the page for landscape
%   read geometry.pdf for detailed page layout information

\usepackage{graphicx} % support the \includegraphics command and options

% \usepackage[parfill]{parskip} % Activate to begin paragraphs with an empty line rather than an indent

%%% PACKAGES
\usepackage{booktabs} % for much better looking tables
\usepackage{array} % for better arrays (eg matrices) in maths
\usepackage{paralist} % very flexible & customisable lists (eg. enumerate/itemize, etc.)
\usepackage{verbatim} % adds environment for commenting out blocks of text & for better verbatim
\usepackage{subfig} % make it possible to include more than one captioned figure/table in a single float
% These packages are all incorporated in the memoir class to one degree or another...
\usepackage{enumitem}
\usepackage{amsmath}
\usepackage{siunitx}
% para los cuadritos en links
%\usepackage[linkbordercolor={0 0 1}, citebordercolor={0 1 0}, urlbordercolor={1 0 0}]{hyperref}
\usepackage[colorlinks=true, linkcolor=black, citecolor=green, urlcolor=red]{hyperref} % solo resalta
\usepackage[spanish]{babel}

\usepackage{booktabs}
\usepackage{array}

%%% HEADERS & FOOTERS
\usepackage{fancyhdr} % This should be set AFTER setting up the page geometry
\pagestyle{fancy} % options: empty , plain , fancy
\renewcommand{\headrulewidth}{0pt} % customise the layout...
\lhead{}\chead{}\rhead{}
\lfoot{}\cfoot{\thepage}\rfoot{}

%%% SECTION TITLE APPEARANCE
\usepackage{sectsty}
\allsectionsfont{\sffamily\mdseries\upshape} % (See the fntguide.pdf for font help)
% (This matches ConTeXt defaults)

%%% ToC (table of contents) APPEARANCE
\usepackage[nottoc,notlof,notlot]{tocbibind} % Put the bibliography in the ToC
\usepackage[titles,subfigure]{tocloft} % Alter the style of the Table of Contents
\renewcommand{\cftsecfont}{\rmfamily\mdseries\upshape}
\renewcommand{\cftsecpagefont}{\rmfamily\mdseries\upshape} % No bold!

%%% END Article customizations

%%% The ``real'' document content comes below...



\title{
	\vspace{-2cm} % Ajusta este valor para subir/bajar todo el bloque
	\centering
	\LARGE \textbf{Monografía} \\[0.8cm]
	\Huge \textbf{Identificación de sistemas no lineales por medio de redes neuronales auto-regresivas} \\[1.5cm]
	\large
	\textbf{Universidad de Buenos Aires} \\
	Facultad de Ingeniería \\[0.5cm]
	\normalsize
	\begin{tabular}{r l}
		\textbf{Alumno:} & Ignacio Ezequiel Cavicchioli \\
		\textbf{Padrón:} & 109428 \\
		\textbf{Email:} & icavicchioli@fi.uba.ar
	\end{tabular}
}
\author{} % Dejamos vacío porque el autor ya está en el título
\date{\vspace{0.5cm} \today} % Fecha actual

\begin{document}
\maketitle

%\tableofcontents

\begin{abstract}
	\noindent

	En el presente trabajo se estudia la identificación y el control de un sistema no lineal de tanques acoplados mediante el uso de modelos lineales y modelos basados en redes neuronales. A partir de un modelo físico no lineal continuo, se obtiene una representación en tiempo discreto que se utiliza como referencia para simulación y validación.

	La identificación del sistema se aborda mediante el entrenamiento de redes neuronales auto-regresivas, utilizando datos generados a partir de la planta no lineal. El desempeño de estos modelos se evalúa y se compara con el de modelos lineales obtenidos tanto por linealización analítica como mediante herramientas de identificación. Los resultados muestran que, dentro de un régimen de operación acotado, las redes neuronales permiten representar con mayor precisión la dinámica del sistema, aunque a costa de un mayor esfuerzo de ajuste.

	Asimismo, se analiza un enfoque híbrido que combina un modelo lineal con una red neuronal destinada a compensar el error de modelado, el cual no presenta mejoras significativas respecto de los enfoques puramente lineales o puramente no lineales. Finalmente, se estudia el diseño de controladores a partir de modelos neuronales y se evalúa la posibilidad de clonar un controlador PID mediante una red neuronal, poniendo en evidencia limitaciones en términos de robustez y rechazo de perturbaciones.

	\vspace{0.5em}
	\noindent
	\textbf{Palabras clave:} identificación de sistemas, redes neuronales, sistemas no lineales, control PID.
\end{abstract}

\vspace{1cm}

\newpage
% TABLA DE CONTENIDOS
\tableofcontents
\newpage

% CONTENIDO PRINCIPAL
\section{Introducción}
\label{sec:introduccion}

Las redes neuronales en sus múltiples formas constituyen sistemas no lineales con un amplio alcance de aplicación en campos como la biología, neurociencia y, al que se avoca este trabajo, aprendizaje automático (\textit{machine learning}, ML). En particular, nos interesa centrarnos en las aplicaciones de las redes neuronales en el campo de control automático. Esta doctrina se encarga del diseño sistemas para regular, guiar o estabilizar procesos de manera autónoma, mediante la realimentación y corrección continua de errores.

La denominada ``caja de herramientas'' de aquellos en el área de control está compuesta por ciertos artefactos matemáticos que permiten encarar estos problemas, como la linealización de un sistema, el control PID, realimentación de estados, \textit{loop-shaping}, observadores, etc. Lo que no se ha tocado en las materias de control son las estrategias no lineales. En líneas generales, todos los sistemas reales exhiben cierto grado de no linearidad, lo que implica que las estrategias de control lineales son válidas siempre que las no linealidades sean despreciables. Análogamente, las herramientas de identificación de sistemas basadas en la linealización de un sistema fallaran en modelar las no linealidades de estos.

Este trabajo va a ahondar sobre el uso de redes neuronales en la doctrina de control automático, específicamente como identificadores de sistemas y clonadores de controladores.


\section{Sistema elegido}

El sistema elegido está compuesto por 2 tanques de agua de dimensiones diferentes, dónde el primer tanque actúa como una cisterna amortiguadora de fluctuaciones en el caudal seguido de un reservorio que ajusta el caudal de salida. Este tipo de esquemas podrían encontrarse en procesos industriales que requieren de un caudal estabilizado.

\begin{figure}[h!]
	\centering
	\includegraphics[width=0.7\linewidth]{imgs/tanques}
	\caption{Sistema elegido}
	\label{fig:tanques}
\end{figure}

La figura \ref{fig:tanques} muestra el sistema recién descripto, agregando los caudales de entrada y salida $u$ e $y$. Ambos caudales son muestreados a \SI{1}{\Hz}, que debería ser más que suficiente para este tipo de dinámicas lentas. Tanto la tubería que une los tanques como la que sale del segundo tienen cierto coeficiente hidráulico asociado a su geometría, siendo estos $K_{12}$ y $K_2$ respectivamente.

\newpage

Las razones por la cuales se eligió este sistema son las siguientes:
\begin{itemize}
	\item Simplicidad: Es un sistema de vector de estados de 2 dimensiones, simple de modelar, linealizar, simular y controlar.
	\item No linealidad: Como se va a ver en el inciso matemático, el sistema no es lineal, que sería un requisito si se está intentando evaluar la capacidad de copiar no linealidades de las redes neuronales.
	\item Realismo: Se prefirió elegir un sistema que sea fácil de entender pero real, no una reducción de un sistema más complejo.
\end{itemize}


\subsection{Modelo matemático}

El modelado de este sistema hace uso de varias leyes físicas de la hidráulica. Primero, se plantea que el líquido es incompresible, por lo que el volumen solo varía si los caudales de entrada y salida no son iguales.

\begin{equation}
	\frac{dV}{dt} = \sum q_{in} - \sum q_{out}
	\label{eq:1}
\end{equation}


Además, en este caso que el área es independiente del nivel de agua, el volumen es función del área del tanque y su superficie. Podemos derivar respecto del tiempo.

\begin{equation}
	V(t) = A \cdot h(t) \overset{d/dt}{\longrightarrow } \frac{dV}{dt} = A \cdot \frac{dh(t)}{dt}
	\label{eq:2}
\end{equation}

Luego se aplica la ley de caudal, que relaciona el caudal entre 2 puntos con la diferencia de nivel entre ellos mismos.

\begin{equation}
	q = k\,\sqrt{2g}\,\sqrt{\Delta h}
	\label{eq:3}
\end{equation}

El caudal entre los tanques resulta:

\begin{equation}
	q_{12}(t) = k_{12}\,\sqrt{2g}\,\sqrt{h_1(t) -h_2(t)}
	\label{eq:4}
\end{equation}

El caudal de salida del segundo tanque, que también es la salida $y$, es:
\begin{equation}
	q_{2}(t) = y(t) = k_{2}\,\sqrt{2g}\,\sqrt{h_2(t)}
		\label{eq:5}
\end{equation}


Ahora, se plantea un balance en cada tanque igualando \eqref{eq:1} y \eqref{eq:2}.

\begin{equation}
	A_1 \cdot \frac{dh_1}{dt} = u(t) - q_{12}(t)
	\label{eq:6}
\end{equation}

\begin{equation}
	A_2 \cdot \frac{dh_2}{dt} = q_{12}(t) - q_{2}(t) =  q_{12}(t) - y(t)
	\label{eq:7}
\end{equation}

sustituyendo con \eqref{eq:4} :

\begin{equation}
	A_1 \cdot \frac{dh_1}{dt} = u(t) - k_{12}\,\sqrt{2g}\,\sqrt{h_1(t) -h_2(t)}
	\label{eq:8}
\end{equation}

\begin{equation}
	A_2 \cdot \frac{dh_2}{dt} = k_{12}\,\sqrt{2g}\,\sqrt{h_1(t) -h_2(t)} -  k_{2}\,\sqrt{2g}\,\sqrt{h_2(t)}
	\label{eq:9}
\end{equation}

Finalmente, se asume que:
$$
h_1 \ge h_2 \ge 0
$$

Con todo esto se plantea el espacio de estados\textbf{ no lineal} y continuo, con la forma de a continuación:

\begin{equation}
	\frac{d}{dt}
	\begin{bmatrix}
		h_1
		\\
		h_2
	\end{bmatrix} =
	\begin{bmatrix}
		(u - k_{12}\,\sqrt{2g}\,\sqrt{h_1 -h_2})\cdot \frac{1}{A_1}
		\\
		(k_{12}\,\sqrt{2g}\,\sqrt{h_1 -h_2} -  k_{2}\,\sqrt{2g}\,\sqrt{h_2})\cdot \frac{1}{A_2}
	\end{bmatrix}
	\label{eq:ss1}
\end{equation}


\begin{equation}
	y=k_{2}\,\sqrt{2g}\,\sqrt{h_2}
	\label{eq:ss2}
\end{equation}

Las expresiones \eqref{eq:ss1} y \eqref{eq:ss2} se van a linealizar en torno al punto de equilibrio $(x_e,u_e)$ y las constantes físicas indicadas abajo.

\begin{itemize}
	\item $g = 9.81$
	\item $A_1 = 0.342$, $A_2 = 0.126$
	\item $k_{12} = 5 \times 10^{-4}$, $k_2 = 1 \times 10^{-3}$
	\item $h_{1s} = 1.019$, $h_{2s} = 0.204$
	\item $u_s = 0.002$
\end{itemize}

%g   = 9.81;
%A1  = 0.015;
%A2  = 0.02;
%k12 = 5e-4;
%k2  = 1e-3;
%h1s = 1.019;
%h2s = 0.204;
%us  = 0.002;

Las variables de estado elegidas se redefinen como variaciones en torno a ese mismo estado, por lo que de ahora en más las alturas $h_1$ y $h_2$ no son las mismas que en la planta no lineal. El proceso arranca planteando la linealización en sí, que se ve en la ecuación \eqref{eq:12}. La expresión \eqref{eq:13} se cumple por definición del punto $(x_e,u_e)$. En \eqref{eq:14a} y \eqref{eq:14b} se obtiene la matriz A del espacio de estados lineal. En \eqref{eq:15} se obtiene la matriz B, y en \eqref{eq:17}, la C.

Las expresiones \eqref{eq:16} y \eqref{eq:17} constituyen el espacio de estados lineal para la dinámica de los tanques.

\begin{equation}
\overset{\,\circ }{X} = \overset{\,\circ }{\begin{bmatrix}
		h_1
		\\
		h_2
\end{bmatrix}} =f(x_e,u_e) + \frac{df}{d x}|_{(x_e,u_e)} (x-x_e) +  \frac{df}{d u}|_{(x_e,u_e)} (u-u_e)
\label{eq:12}
\end{equation}

\begin{equation}
f(x_e,u_e)=0
\label{eq:13}
\end{equation}

\begin{equation}
\frac{df}{d x}|_{(x_e,u_e)} = \begin{bmatrix}
	\frac{-k_{12} \sqrt{2g}}{A_1 \cdot 2 \sqrt{h_1-h_2}}
	&
	\frac{k_{12} \sqrt{2g}}{A_1 \cdot 2 \sqrt{h_1-h_2}}
	\\
	\frac{k_{12} \sqrt{2g}}{A_2 \cdot 2 \sqrt{h_1-h_2}}
	&
	\frac{-k_{12} \sqrt{2g}}{A_2 \cdot 2 \sqrt{h_1-h_2}} - \frac{k_{2} \sqrt{2g}}{A_2 \cdot 2 \sqrt{h_2}}
\end{bmatrix}
|_{(x_e,u_e)}
\label{eq:14a}
\end{equation}

\begin{equation}
	\frac{df}{d x}|_{(x_e,u_e)} =
	 \simeq
	\begin{bmatrix}
		-0.00359
		&
		0.000359
		\\
		0.00976
		&
		-0.04878
	\end{bmatrix}
	\label{eq:14b}
\end{equation}


\begin{equation}
\frac{df}{d u}|_{(x_e,u_e)} = \begin{bmatrix}
	\frac{1}{A_1}
	\\
	0
\end{bmatrix}|_{(x_e,u_e)}=
\begin{bmatrix}
	2.92
	\\
	0
\end{bmatrix}
\label{eq:15}
\end{equation}


\begin{equation}
\overset{\,\circ }{\begin{bmatrix}
		h_1
		\\
		h_2
\end{bmatrix}} =
	\begin{bmatrix}
	-0.00359
	&
	0.000359
	\\
	0.00976
	&
	-0.04878
\end{bmatrix}
\begin{bmatrix}
	h_1
	\\
	h_2
\end{bmatrix}
+
\begin{bmatrix}
	2.92
	\\
	0
\end{bmatrix} u
\label{eq:16}
\end{equation}

\begin{equation}
y = \begin{bmatrix}
	0 & 0.0049
\end{bmatrix} \begin{bmatrix}
	h_1
	\\
	h_2
\end{bmatrix}
\label{eq:17}
\end{equation}


Además de usar este modelo matemático, se dispone de un sistema en espacio de estados de misma dimensión estimado a partir del \textit{dataset} de 14400 muestras (explicado más adelante) usando el \textit{toolbox} correspondiente de \textit{MATALB}. La idea es poder contrastar la calidad de este sistema lineal identificado con la de los modelos no lineales también identificados.

\newpage
\subsection{Simulaciones}

Para esta monografía se decidió hacer uso de \textit{scripts} \textit{MATLAB} y el entorno de \textit{Simulink} debido a la versatilidad que trae en lo que es simulación de sistemas, además que es la herramienta usada en las materias de control automático. La figura \ref{fig:pnolin} muestra el sistema no lineal armado, que simula la planta en tiempo real.

\begin{figure}[h!]
	\centering
	\includegraphics[width=0.5\linewidth]{imgs/P_no_lin}
	\caption{Planta no lineal armada en \textit{simulink}}
	\label{fig:pnolin}
\end{figure}


\begin{figure}[h!]
	\centering
	\includegraphics[width=0.8\linewidth]{imgs/P_no_lin_muestreada}
	\caption{Muestreo de planta no lineal}
	\label{fig:pnolinmuestreada}
\end{figure}

La figura \ref{fig:pnolinmuestreada} muestra el sistema de \textit{simulink} que realiza el muestreo de la planta. La entrada $u$ es una secuencia de escalones de amplitudes aleatorias (ruido blanco gaussiano) alrededor del $10 \%$ del punto operativo. Esto se hizo para poder tener una buena variedad de respuestas al escalón, que se espera ayude a que la red aprenda la dinámica subyacente.

Como el muestreo se realizó a \SI{1}{\Hz}, se decidió generar un \textit{dataset} de 4 horas (14400 muestras), y otro de 1 hora (3600 muestras). La intención es observar cuanto empeora la \textit{performance} de la red con menos muestras de entrenamiento. Como ya se explicó, estos sets de muestras están contenidos en una vecindad del punto operativo, y no son representativos de todo el espacio de estados del sistema, sino que solo de la porción simulada.


\section{Identificación de sistemas}
\label{subsec:ids}

La primer experiencia de esta monografía se centra en la temática de identificación de sistemas a partir de muestras del mismo, abordado desde el lado de redes neuronales. Particularmente, se propone entrenar una red neuronal para que aprenda la dinámica de la planta, y que pueda reproducirla fehacientemente.


\subsection{Suposiciones y decisiones}

Con el objetivo de asegurar resultados conmensurables, los experimentos se armaron y realizaron siguiendo los siguientes preceptos:

\begin{enumerate}
	\item La única métrica de comparación elegida es el RMSE (ec. \eqref{RMSE}). Este se calcula sobre las secuencias de salida de todas las redes entrenadas.

	\begin{equation}
		RMSE = \sqrt{\frac{1}{n} \sum ^n _{i=1} (\hat{x} - x)^2  }
		\label{RMSE}
	\end{equation}

	\item El RMSE se calculó sobre la secuencia de datos de salida pero sin incluir el transitorio inicial. Esto es porque el transitorio inicial no está bien representado en los datos de entrenamiento.
	\item El RMSE se usó para evaluar el funcionamiento en una región acotada del espacio de estados, no la capacidad de extrapolación.

	\item Todos los modelos deben poder usarse de forma auto-regresiva, es decir, realimentados con sus propias salidas. Esto conllevó que los entrenamientos se tuvieran que realizar hasta que se observase convergencia en la simulación.

	\item La cantidad de \textit{epochs} y la cantidad de intentos de entrenamiento no son fijas, sino que se ajustaron empíricamente,  asegurando el cumplimiento del ítem 2.

	\item Los datos se separaron en \textit{train} y \textit{test} en una proporción de $85\%$ a $/15\%$. La separación se realizó de forma secuencial, es decir, se tomo el primer $85\%$ de las muestras para entrenar y el resto para evaluar, manteniendo cierta semblanza al orden temporal. Se podría argumentar que las muestras de evaluación no necesariamente se van a distribuir idénticamente que las de entrenamiento, pero se priorizó variedad de muestras, y el hecho de que los escalones se generaron de forma aleatoria debería ayudar.

	\item Se aplicó una normalización en media y varianza a los datos previo a entrenar. Se espera que esto mejore la \textit{performance} (a entradas más espaciadas, pesos más separados) y la convergencia en el \textit{fitting}.
\end{enumerate}



Con esto dicho, se procede a los ensayos.

\subsection{MLP de 1 capa oculta}

\subsubsection{Introducción}

El primer \textit{approach} pensado es usar un MLP de 1 capa oculta y entrenarlo en base a los datos de la planta en una configuración auto-regresiva como la de la figura \ref{fig:redautoreg}. Dado lo visto en la materia, se espera que el MLP logre captar las no-linealidades de la planta con una capacidad que aumenta con la cantidad de neuronas en su capa oculta. En palabras más simples, se tiene la expectativa que los modelos más chicos tengan peor desempeño que los grandes.

\begin{figure}[h!]
	\centering
	\includegraphics[width=0.7\linewidth]{imgs/red_autoreg}
	\caption{Modelo de red}
	\label{fig:redautoreg}
\end{figure}


El vector de datos de entrada $\mathbf{x}(n)$ elegido consta de 10 muestras previas de $y$ y la referencia actual $u$. La salida esperada de la red es la siguiente muestra, efectivamente entrenando un predictor del siguiente estado.

\[
\mathbf{x}(n) =
\big[
y(n),\; y(n-1),\; \dots,\; y(n-9),\; u(n)
\big]
\]

\[
\hat{y}(n+1) = f\big(
y(n),\; y(n-1),\; \dots,\; y(n-9),\; u(n)
\big)
\]

Algunos lectores podrían argumentar que sería injusto comparar un modelo lineal que usa la salida actual con uno auto-regresivo de orden 10, pero la elección no es arbitraria, sino que basada en el hecho de que el sistema es lento. Si se usaran pocos retardos, escalones de entrada pequeños causarían que el vector de entrada sea un apilamiento de números casi idénticos, posiblemente dificultando la inferencia de la dinámica. En cambio, una ventana temporal mayor permite que los cambios exponenciales se observan de forma más completa y la red pueda capturar la velocidad de variación correcta.

Todo esto introduce una asimetría respecto del modelo lineal, que usa solo el estado actual. Sin embargo, como el objetivo principal es evaluar la capacidad de las redes neuronales para reproducir la dinámica del sistema, se consideró aceptable priorizar una buena representación temporal.

\subsubsection{Entrenamiento}

Como se adelantó previamente, se decidió crear con 2 \textit{datasets} así que los experimentos van a verse duplicados. Para esta parte se decidió entrenar redes de 20, 10, 5 y 2 preceptrones en la capa oculta.

Algunos puntos interesantes a destacar del entrenamiento son:

\begin{itemize}
	\item Se entrenó por una cantidad fija de \textit{epochs}, permitiendo interrumpir cuando el gradiente era menor a $1e-9$ (que nunca sucedió).
	\item El proceso de entrenamiento fue manejado por la función \textit{train}\footnote{\href{https://la.mathworks.com/help/deeplearning/ref/network.train.html}{Documentación oficial}} del \textit{Deep learning toolbox} de \textit{MATLAB}.
	\item En general, los modelos pequeños requirieron de más intentos de entrenamiento para llegar a un sistema que cumpliera con los requisitos planteados. El parámetro modificado fue cantidad de \textit{epochs}.
	\item Hubo casos en los que los sistemas obtenidos tenían un estado estacionario oscilante, invariante respecto la acción de control. Esto fue considerado un espurio llamativo, aunque lamentablemente no se guardaron imágenes.
	\item El modelo lineal estimado se obtuvo usando la herramienta de identificación de sistemas propia de \textit{MATLAB}.
\end{itemize}



\subsubsection{Resultados}

Las figuras del apéndice \ref{ap1} muestran las señales de interés, incluyendo la entrada $u$, la salida $y$ real, la $y$ del sistema linealizado y la salida de cada red entrenada. Las imágenes se trasladaron a un apéndice para que no estorben en la lectura.


Mediante inspección visual, la respuesta real (fig. \ref{fig:salida-y}) y las respuestas de las redes neuronales aparecen casi indistinguibles, salvo por los transitorios iniciales. Sin embargo, lo mismo se observa para las respuestas obtenidas de los sistemas lineales.
Por esto, se presenta un cuadro con los RMSE de todas las respuestas, calculado usando de referencia la salida del sistema no lineal original. Las secuencias fueron tomadas a partir de la muestra número 2000, evitando los transitorios, tal como se dijo que se iba a hacer.

\begin{table}[h]
	\centering
	\begin{tabular}{l c}
		\hline
		\textbf{Modelo} & \textbf{RMSE} \\
		\hline
		MLP 20--14400             & $2.36 \times 10^{-7}$ \\
		MLP 10--14400             & $3.24 \times 10^{-7}$ \\
		MLP 5--14400              & $1.06 \times 10^{-6}$ \\
		Modelo lineal (estimado)  & $1.80 \times 10^{-6}$ \\
		MLP 5--3600               & $1.95 \times 10^{-6}$ \\
		MLP 2--14400              & $2.01 \times 10^{-6}$ \\
		MLP 20--3600              & $6.71 \times 10^{-6}$ \\
		Modelo lineal (matemático)      & $6.83 \times 10^{-6}$ \\
		MLP 2 --3600               & $1.88 \times 10^{-5}$ \\
		MLP 10--3600              & $2.46 \times 10^{-5}$ \\
		\hline
	\end{tabular}
	\caption{Comparación del error cuadrático medio (RMSE) entre los distintos modelos evaluados}
	\label{tab:rmse_comparacion}
\end{table}
\clearpage
\subsubsection{Análisis de resultados}

A partir de los resultados expuestos en el cuadro \ref{tab:rmse_comparacion}, se notan tendencias en la \textit{performance} de los varios modelos analizados. Primero, los modelos entrenados en base a más muestras (14400) tienen RMSE inferiores a los entrenados en base al set de 3600 muestras - que es consistente con las hipótesis antes mencionadas de la capacidad de captar no-linealidades.

En segundo lugar, el sistema lineal obtenido matemáticamente (apodado ``matemático'' en el cuadro), logró mejores ajustes que dos redes por un orden de magnitud. Esto puede deberse a que el modelo lineal es muy bueno o que las redes resultaron \textit{sub-par}. Dicho esto, es inferior que el resto de las redes, incluyendo 2 entrenadas con el \textit{dataset} pequeño, dando a entender que, incluso con pocas muestras se puede lograr un modelo no lineal mejor que uno simple derivado matemáticamente.

El ``podio'' de los resultados está compuesto de 3 redes neuronales y el modelo lineal estimado, todos entrenadas con el \textit{dataset} grande . La mejor red supera al modelo lineal por $7.6$ veces, y no sorprende que sea la red más grande (20 unidades en la capa oculta).


Se cree que el orden de auto-regresividad elegido (10 muestras previas) también influenció los resultados, pero se desconoce su alcance.


En líneas generales, los resultados apuntan a que, para la auto-regresividad elegida, la cantidad de muestras disponibles permite el entrenamiento de modelos más complejos, que a su vez llegan a precisiones superiores que sus contrapartes lineales,

Ahora bien, se debe resaltar que ninguno de los modelos obtenidos es inherentemente malo, sino que el tipo de modelo a usar queda determinado por los requerimientos de la aplicación. Los experimentos recién detallados solo indican que una forma de lograr respuestas más similares a la real es por el uso de sistemas no lineales en la identificación.

\newpage
\subsection{Sistema lineal asistido}

\subsubsection{Introducción}

El segundo enfoque ideado surge como una posible avenida de mejora del \textit{approach} anterior: Si se puede lograr un buen desempeño con un modelo lineal, tal vez se pude corregir el error de la estimación lineal por medio de una red neuronal que aprenda el error de estimación. Se supone que, teniendo el sistema lineal como estimador del estado, la red podría dedicar toda su estructura a aprender la codificación que lleva la estimación lineal a la real, logrando una mejor estimación.

La figura \ref{fig:red_autoreg2} muestra el sistema recién descripto. El hiperparámetro $m$ se va a ajustar manualmente para minimizar el error de entrenamiento y evaluación.


\begin{figure}[h!]
	\centering
	\includegraphics[width=0.9\linewidth]{imgs/red_autoreg2}
	\caption{Modelo de red}
	\label{fig:red_autoreg2}
\end{figure}

Inicialmente, se espera que este sistema logre mejor precisión que si solo se usara el lineal, pero no se puede afirmar a priori si va a ser mejor que las otras redes.

Se va a usar el modelo lineal identificado por \textit{MATLAB}, y no el obtenido por medio del desarrollo matemático debido a 2 razones:
\begin{itemize}
	\item El modelo identificado dió mejores resultados.
	\item El uso del modelo identificado tiene más sentido en el contexto de esta monografía, que se centra en la identificación de sistemas, y no su derivación matemática.
\end{itemize}


\subsubsection{Entrenamiento}

El proceso de \textit{fitting} comenzó generando un conjunto de datos auxiliar, formado por el error de estimación del sistema lineal $e =y - y_{lin}$, la salida lineal $y_{lin}$ y la entrada de los sistemas.
A partir de este conjunto, se construyeron los vectores de entrada a las redes ya especificados (los retardos de la salida lineal y la entrada $u$), mientras que como objetivo se empleó el error de estimación.

Como los resultados del entrenamiento no eran buenos, se decidió revertir la función de entrenamiento a su estado original, con los conjuntos de \textit{train}, \textit{test} y \textit{validation}.

\subsubsection{Resultados}

El cuadro~\ref{tab:resultados_cascada} muestra el RMSE de cada uno de los experimentos realizados. Cada prueba intentó mejorar la anterior de alguna forma, sea reduciendo la dimensión de la entrada o la cantidad de neuronas. La columna de ``{Figuras}'' referencia las respuestas en el tiempo de cada prueba, ubicadas en el apéndice \ref{ap2} para que no entorpezcan la lectura.


\begin{table}[h!]
	\centering
	\begin{tabular}{c p{7cm} c c}
		\toprule
		\textbf{Prueba} & \textbf{Descripción de la red} & \textbf{RMSE} & \textbf{Figuras} \\
		\midrule
		1 &MLP de 20 unidades en la capa oculta.

		Usó $y_{\text{lin}}$ desde $n$ hasta $n-9$.
		\vspace{2mm}
		 &
		$8.71 \times 10^{-6}$ &
		Figs.~\ref{fig:prueba11}, \ref{fig:prueba12} \\

		2 &
		MLP de 20 unidades en la capa oculta.

		Usó únicamente $y_{\text{lin}}(n)$. \vspace{2mm}&
		$9.18 \times 10^{-6}$ &
		Figs.~\ref{fig:prueba21}, \ref{fig:prueba22} \\

		3 &
		MLP de 10 unidades en la capa oculta.

		Usó $y_{\text{lin}}$ desde $n$ hasta $n-4$.\vspace{2mm} &
		$6.21 \times 10^{-6}$ &
		Figs.~\ref{fig:prueba31}, \ref{fig:prueba32} \\

		4 &
		MLP de 5 unidades en la capa oculta.

		Usó $y_{\text{lin}}$ desde $n$ hasta $n-4$.\vspace{2mm} &
		$5.78 \times 10^{-6}$ &
		Figs.~\ref{fig:prueba41}, \ref{fig:prueba42} \\


		5 &
		MLP de 5 unidades en la capa oculta.

		Usó $y_{\text{lin}}$ desde $n$ hasta $n-9$. &
		$5.87 \times 10^{-6}$ &
		Figs.~\ref{fig:prueba51}, \ref{fig:prueba52} \\
		\bottomrule
	\end{tabular}
	\caption{Resultados de las pruebas}
	\label{tab:resultados_cascada}
\end{table}



\subsubsection{Análisis de resultados}

Antes que nada, nótese que, si bien los mejores sistemas obtenidos solo son marginálmente mejores que el sistema lineal desarrollado matemáticamente, todos ellos implican un empeoramiento respecto del modelo lineal a partir del cual fue construido el enfoque. En este sentido, la comparación directa pierde relevancia, ya que el deterioro introducido por la identificación sugiere la existencia de un problema con el enfoque.

Las gráficas de las salidas de todas las pruebas hechas muestran espurios generados por la red neuronal, no están en la salida lineal, que empeoran el RMSE y constituyen transiciones de estados que la planta original no podría experimentar nunca, tales como escalones a la salida. Esto claramente es un efecto indeseado introducido por las redes neuronales entrenadas.

Por último, otro punto desfavorable para estos modelos híbridos es que su obtención tomó más tiempo que la de las redes neuronales solas o incluso del modelo lineal estimado.


Todo lo observado apunta a que estos sistemas son inferiores a las alternativas vistas antes tanto en tiempo como en ajuste. No obstante, es probable que, con un cambio de enfoque y arquitectura, la idea de estimar el error $y - y_{lin}$ de forma no lineal si sea viable.

\newpage
\subsection{Discusión general de resultados}

En luz de los resultados ya expuestos en los incisos previos, se podrían hacer las siguientes afirmaciones:

\begin{itemize}
	\item Las redes neuronales sirven para hacer identificación de sistemas, y pueden lograr mejores ajustes que los modelos lineales.
	\item El tamaño de las redes no es algo de menor importancia ya que parece condicionar la capacidad de ajuste final. Deberá se elegida a conciencia y por medio de ``prueba y error''.
	\item Se observó una relación positiva entre la cantidad de neuronas en la capa oculta y el ajuste a la salida real, para un orden de auto-regresividad dado (10 muestras previas).
	\item Se notó que el uso de más muestras permite obtener redes neuronales con mejor ajuste.
	\item Parecería preferible elegir un \textit{approach} puramente lineal o no lineal para la identificación que intentar fusionarlos. Esto último toma más tiempo y los resultados obtenidos no lo justifican.
\end{itemize}

Es clave entender que el uso de un sistema no lineal en el área de identificación de sistemas puede o no resultar un exceso. Como se dijo antes, la complejidad del modelo requerido queda completamente determinada por la aplicación. En este caso de 2 tanques de agua, un sistema no lineal es innecesario, pero para procesos ``menos lineales'' podría darse que el error de la estimación lineal es inadmisible, requiriéndose usar técnicas como las usadas.

\newpage

\section{Control de sistemas}
\label{sec:control}

Habiendo concluido la sección de identificación de sistemas, se puede avanzar al segundo tema de esta monografía, que es el control. La primer idea es mostrar que el modelo no lineal compuesto por una red neuronal efectivamente sirve para diseñar un controlador. Luego, se propone clonar un controlador (como se hizo con la planta no lineal) para analizar su desempeño a lazo cerrado.

En esta sección se evita la mención de cotas como márgenes de fase, ganancia y estabilidad, debido a que no son relevantes para la monografía y, como indica la p.581, sección 19.11 del libro ``\textit{Control System Design}'', muchas nociones comunes para sistemas lineales no aplican para los no lineales.

\subsection{Diseño de controlador con modelo no lineal identificado como referencia}

Para esta experiencia, se tomó la red neuronal con mejor ajuste del inciso \ref{subsec:ids} y se diseñó un controlador del tipo PID, buscando una respuesta veloz pero no sub-amortiguada. Luego, se verificó su funcionamiento cambiando la red neuronal por el modelo no lineal real.

\subsubsection{Teoría del control PID}

Citando el capítulo 6 del libro ``\textit{Control System Design}'',  un controlador PID - proporcional, integral y derivativo - es una estructura de control casi universalmente usada en la industria por su simpleza. Una posible transferencia completa de este tipo de controlador es la siguiente:

$$
C_{PID}(s) = K_p + \frac{K_i}{s} + \frac{K_d s}{\gamma _d K_d s +1}
$$

\begin{itemize}
	\item \textbf{Acción proporcional $K_p$}: genera una acción de control proporcional al error. Estabiliza plantas ya estables, pero no corrige el error en estado estacionario.
	\item \textbf{Acción integral $K_i$}: produce una acción de control proporcional al error acumulado. Corrige el error en estado estacionario para referencias tipo escalón pero puede causar problemas de fase debido al polo en el origen.
	\item \textbf{Acción derivativa $K_d$}: devuelve una acción de control proporcional a la derivada del error. En la práctica, la existencia de ruido en los sensores y mediciones puede introducir derivadas elevadas y, por ende, acciones de control desmedidas. Hay que usarla con cuidado y filtrando adecuadamente.
\end{itemize}

No se eligió otra estrategia de control porque el sistema es simple y estable a lazo abierto.

\newpage
\subsubsection{Diseño del controlador y resultados}

El diseño de un PID es un proceso iterativo en el que se van ajustando los coeficientes $K_p$, $K_i$ y $K_d$ hasta obtener la respuesta deseada. En este caso particular, el proceso se llevó a cabo en \textit{simulink}, y la figura \ref{fig:pid-nn-simulink} muestra el lazo final. La imagen \ref{fig:RTA-pid-nn-simulink} muestra las salidas a lazo abierto y cerrado, la acción de control y la referencia.


\begin{figure}[h!]
	\centering
	\includegraphics[width=0.9\linewidth]{imgs/pid NN simulink}
	\caption{Esquema de control de la red neuronal por PID}
	\label{fig:pid-nn-simulink}
\end{figure}

\begin{figure}[h!]
	\centering
	\includegraphics[width=0.9\linewidth]{imgs/tuned_pidNN}
	\caption{Simulación a lazo cerrado - planta armada con red neuronal}
	\label{fig:RTA-pid-nn-simulink}
\end{figure}

Nótese que la respuesta verde, correspondiente a la salida a lazo cerrado, llega antes que la roja (lazo abierto) al estado estacionario fijado por la referencia. Esto indica que el PID logró acelerar el sistema sin volverlo extremadamente agresivo u oscilante. Además, la acción de control es acotada, sin divergencias. La constante $K_d$ resultó nula, por lo que el control es en realidad un PI pero se va a seguir referenciando como PID por el bloque de \textit{simulink}.

\newpage

Las figuras \ref{fig:pid-nolin-simulink} y \ref{fig:RTA-pid-nolin-simulink} muestran el sistema armado con la planta no lineal y las salidas, tal como antes. Se observa que el controlador diseñado sobre el modelo no lineal, conformado por con redes neuronales, funcionó con la planta real. Esto está alineado con las observaciones de la experiencia de identificación, y corrobora que el sistema identificado por una red neuronal sirve para el diseño de controladores para un punto de operación dado.


\begin{figure}[h!]
	\centering
	\includegraphics[width=0.9\linewidth]{imgs/pid Nolin simulink}
	\caption{Esquema de control de la planta no lineal por PID}
	\label{fig:pid-nolin-simulink}
\end{figure}

\begin{figure}[h!]
	\centering
	\includegraphics[width=0.9\linewidth]{imgs/tuned_pidNolin}
	\caption{Simulación a lazo cerrado - planta no lineal real}
	\label{fig:RTA-pid-nolin-simulink}
\end{figure}

\clearpage

\subsection{Clonado del controlador}

Teniendo un controlador funcional, se procedió a generar muestras de este y clonarlo por medio de una red neuronal. El procedimiento es idéntico al empleado en identificación de sistemas, dónde lo novedoso está en estudiar si una red neuronal puede reemplazar al controlador. Se espera que la red pueda emular al controlador como lo hizo con la planta, pero se duda que capte la esencia de lo que realmente hace (véase la transferencia de un PID previamente estipulada).

\subsubsection{Entrenamiento}

Usando el esquema de la figura \ref{fig:pid-nolin-simulink}, se armó un set de datos de 14400 muestras constituido por la referencia, el error (referencia menos salida), la salida del controlador y la salida de la planta. Se mantuvo un tamaño idéntico al que dió los mejores resultados en la identificación de sistemas.

Como arquitectura, se eligió una red neuronal auto-regresiva de 20 neuronas en su capa oculta que usa de entrada las últimas 10 salidas de la planta, aparte de la referencia y error. Se espera que la redundancia de información de usar la referencia, salida y error mejore el resultado ya que la red no necesita aprender el error a partir de las otras.

La figura \ref{fig:cloncontroltrain} muestra el error de entrenamiento/testeo. Se observa que corta en un punto de relativa convergencia (derivada baja). La imagen \ref{fig:stepnnpid2} contiene unos gráficos que muestran la \textit{performance} de la red respecto de los datos. La identificación parece haber funcionado porque el error de predicción es acotado, lo que da esperanza de que el controlador clonado funcione.




\begin{figure}[h!]
	\centering
	\includegraphics[width=0.8\linewidth]{imgs/clon_control_train}
	\caption{Error de entrenamiento y evaluación de la red}
	\label{fig:cloncontroltrain}
\end{figure}

\begin{figure}[h!]
	\centering
	\includegraphics[width=0.9\linewidth]{imgs/step_NN_PID2}
	\caption{Evaluación de la red}
	\label{fig:stepnnpid2}
\end{figure}

\clearpage

\subsubsection{Resultados}

La figura \ref{fig:stepnnpid} muestra la respuesta al escalón del controlador real y del clonado. Son prácticamente coincidentes, lo que es un indicio de que el entrenamiento funcionó. la figura \ref{fig:stepnnpidaccionconrtol} muestra las acciones de control para las respuestas al escalón; no se ven espurios inadecuados.

\begin{figure}[h!]
	\centering
	\includegraphics[width=0.8\linewidth]{imgs/step_NN_PID}
	\caption{Respuestas al escalón}
	\label{fig:stepnnpid}
\end{figure}


\begin{figure}[h!]
	\centering
	\includegraphics[width=0.8\linewidth]{imgs/step_NN_PID_accionconrtol}
	\caption{Respuestas al escalón - acciones de control}
	\label{fig:stepnnpidaccionconrtol}
\end{figure}



Ahora bien, la imagen \ref{fig:cloncontrolpulsosref} muestra las salidas a lazo cerrado cuando varía la referencia. Se empiezan a observar problemas con el controlador clonado, principalmente que su error en estado estacionario no es nulo, como el del controlador original (el PI/PID). Es más, la figura \ref{fig:cloncontrolpulsosruido}, simulada con el esquema \ref{fig:esquemaruidoentradaplanta}\footnote{Las perturbaciones introducidas son de igual amplitud que los cambios en la referencia de antes ($\pm 10\%$ del estado estacionario) pero centradas en el origen.}, indica que hay algo fundamentalmente mal, ya que el controlador clonado no comprende que el ruido introducido en el lazo se debe eliminar y, en cambio, está respondiendo a estos como si fueran cambios en la referencia.


\begin{figure}[h!]
	\centering
	\includegraphics[width=0.8\linewidth]{imgs/clon_control_pulsos_ref}
	\caption{Respuesta a cambios en la referencia}
	\label{fig:cloncontrolpulsosref}
\end{figure}

\begin{figure}[h!]
	\centering
	\includegraphics[width=0.8\linewidth]{imgs/clon_control_pulsos_ruido}
	\caption{Respuesta a ruido en la salida del controlador}
	\label{fig:cloncontrolpulsosruido}
\end{figure}

\begin{figure}[h!]
	\centering
	\includegraphics[width=0.9\linewidth]{imgs/esquema_ruido_entrada_planta}
	\caption{Esquema de simulación de ruido en la salida del controlador}
	\label{fig:esquemaruidoentradaplanta}
\end{figure}


\clearpage
En retrospectiva, el \textit{dataset} nunca debería haber incluido la referencia, ya que es invariante con las perturbaciones en el lazo, algo que no se pensó hasta que se hicieron los experimentos. por completitud, se entrenó otra red usando un set de datos que usa solo el error del lazo y salida, e incluye muestras obtenidas perturbando a la entrada de la planta (mitad de cambios en la referencia, mitad perturbaciones).

Los resultados se pueden ver en las figuras \ref{fig:rtaescalon2}, \ref{fig:rtaescalon_C}, \ref{fig:prueba_control_cambiado2} y \ref{fig:prueba_control_cambiado}. Parece haber ``aprendido'' el control desde la referencia como antes, aunque con error en estado estacionario, pero no se logró que rechace perturbaciones a la salida del controlador/entrada a la planta.

\begin{figure}[h!]
	\centering
	\includegraphics[width=0.8\linewidth]{imgs/rta_escalon_2}
	\caption{Respuesta al escalón}
	\label{fig:rtaescalon2}
\end{figure}

\begin{figure}[h!]
	\centering
	\includegraphics[width=0.8\linewidth]{imgs/rtaescalon_2C}
	\caption{Respuesta al escalón}
	\label{fig:rtaescalon_C}
\end{figure}

\begin{figure}[h!]
	\centering
	\includegraphics[width=0.8\linewidth]{imgs/prueba_control_cambiado2}
	\caption{Respuesta a cambios en la referencia}
	\label{fig:prueba_control_cambiado2}
\end{figure}

\begin{figure}[h!]
	\centering
	\includegraphics[width=0.8\linewidth]{imgs/prueba_control_cambiado}
	\caption{Respuesta a ruido en la salida del controlador (perturbaciones)}
	\label{fig:prueba_control_cambiado}
\end{figure}
\clearpage
\subsubsection{Análisis de resultados}

Los resultados obtenidos no favorecen la idea de clonar controladores con redes neuronales. Aunque se mantiene la posibilidad de controlar en base a cambios en la referencia, los controladores obtenidos también interpretaron las perturbaciones como acciones de control válidas. Esto resulta en un controlador que amplifica el ruido proveniente del exterior y, por ende, no utilizable en la práctica.

Las redes obtenidas no son más que sistemas que intentaron memorizar salidas a partir de entradas, razón por la cual el error en estado estacionario no es nulo, excepto en ciertos casos. De igual manera se esperaba que las redes no lograran captar la complejidad del PID entero, y es razonable que no pueda copiar una operación de integración (la parte ``I'' del PID). Es posible que cambios en la arquitectura ayuden con el clonado, siendo uno posible el agregado de un integrador como entrada de la red. De esta manera, la red podría usar la integral del error como parte del vector de entrada y aprender la acción de control que lo minimiza.

Igualmente, se destaca que la experiencia si revalidó las capacidades de identificación de sistemas de las redes neuronales. Si no fuera por estas, tampoco se podría controlar desde la referencia como se hizo.

\newpage

\section{Conclusiones}
\label{sec:conclusiones}

En esta monografía se abordó la identificación y el control de un sistema no lineal de tanques acoplados por medio de modelos lineales y sistemas basados en redes neuronales.

La primer experiencia se centró en el entrenamiento de modelos no lineales relativamente variados, y su posterior comparación con sistemas lineales, derivados de la planta original. Se observó que, con la arquitectura y cantidad demuestras adecuadas, las redes neuronales logran captar adecuadamente las dinámicas del sistema dentro del régimen considerado, superando a los modelos lineales. Se destaca que el uso de redes neuronales requiere de más prueba y error que la linealización, pudiendo ser desfavorable en ciertos contextos más acotados en tiempo.

Asimismo, se exploró un enfoque híbrido, que combina modelos lineales con redes neuronales encargadas de estimar el error de modelado. Los resultados mostraron que este esquema no mejora el desempeño del modelo lineal, y solo introduce dinámicas indeseadas.

En lo que respecta el diseño del control, la segunda experiencia, se demostró que un PID diseñado sobre un modelo no lineal de la planta puede ser aplicado exitosamente sobre la planta real. Esto valida el uso de los modelos no lineales como herramienta de identificación de sistemas.

Finalmente, se analizó la posibilidad de clonar el controlador PID por medio de una red neuronal. Los resultados fueron desfavorables: el sistema clonado actúa de forma adecuada ante cambios en la referencia pero se confunde las perturbaciones de lazo con cambios en la referencia, y generando acciones de control indebidas. Esto trae a luz ciertas de las limitaciones de las redes neuronales a la hora de tener que clonar estructuras complejas.

En conjunto, los resultados muestran que las redes neuronales constituyen una herramienta valiosa para la identificación de sistemas no lineales, siempre que su utilización se realice con criterio y analizando el compromiso entre complejidad y desempeño.






\section{Referencias}
\begin{itemize}
	\item Material de la materia ``Control Automático''.
	\item Control System Design. Autores: Graham C. Goodwin, Stefan F. Graebe, Mario E. Salgado. Año: 2000
	\item \href{https://en.wikipedia.org/wiki/Neural_network_(machine_learning)}{``Neural network (machine learning)'', Wikipedia}
	\item \href{https://en.wikipedia.org/wiki/Machine_learning}{``Machine learning'', Wikipedia}
	\item \href{https://en.wikipedia.org/wiki/Neural_network}{``Neural network'', Wikipedia}
	\item \href{https://la.mathworks.com/help/deeplearning/ug/introduction-to-neural-network-control-systems.html}{``Introduction to neural network control systems'', \textit{MATLAB resources}}
\end{itemize}

\newpage

\section{Apéndice 1 - Resultados de la primer experiencia de identificación}
\label{ap1}

\begin{figure}[h!]
	\centering
	\includegraphics[width=0.8\linewidth]{imgs/entrada u}
	\caption{Entrada $u$}
	\label{fig:entrada-u}
\end{figure}

\begin{figure}[h!]
	\centering
	\includegraphics[width=0.8\linewidth]{imgs/salida y}
	\caption{Salida $y$ de la planta no lineal}
	\label{fig:salida-y}
\end{figure}


\begin{figure}[h!]
	\centering
	\includegraphics[width=0.8\linewidth]{imgs/y e ylin}
	\caption{Comparación entre salida no lineal y lineal}
	\label{fig:y-e-ylin}
\end{figure}

\begin{figure}[h!]
	\centering
	\includegraphics[width=0.8\linewidth]{imgs/y e ylin est}
	\caption{Comparación entre salida no lineal y lineal  del modelo estimado}
	\label{fig:y-e-ylin-est}
\end{figure}

\begin{figure}[h!]
	\centering
	\includegraphics[width=0.8\linewidth]{imgs/MLP 20 14400}
	\caption{Salida del MLP de 20 neuronas en capa oculta - \textit{dataset} de 14400 muestras}
	\label{fig:mlp-20-14400}
\end{figure}

\begin{figure}[h!]
	\centering
	\includegraphics[width=0.8\linewidth]{imgs/MLP 10 14400}
	\caption{Salida del MLP de 10 neuronas en capa oculta - \textit{dataset} de 14400 muestras}
	\label{fig:mlp-10-14400}
\end{figure}

\begin{figure}[h!]
	\centering
	\includegraphics[width=0.8\linewidth]{imgs/MLP 5 14400}
	\caption{Salida del MLP de 5 neuronas en capa oculta - \textit{dataset} de 14400 muestras}
	\label{fig:mlp-5-14400}
\end{figure}

\begin{figure}[h!]
	\centering
	\includegraphics[width=0.8\linewidth]{imgs/MLP 2 14400}
	\caption{Salida del MLP de 2 neuronas en capa oculta - \textit{dataset} de 14400 muestras}
	\label{fig:mlp-2-14400}
\end{figure}


\begin{figure}[h!]
	\centering
	\includegraphics[width=0.8\linewidth]{imgs/MLP 20 3600}
	\caption{Salida del MLP de 20 neuronas en capa oculta - \textit{dataset} de 3600 muestras}
	\label{fig:mlp-20-3600}
\end{figure}

\begin{figure}[h!]
	\centering
	\includegraphics[width=0.8\linewidth]{imgs/MLP 10 3600}
	\caption{Salida del MLP de 10 neuronas en capa oculta - \textit{dataset} de 3600 muestras}
	\label{fig:mlp-10-3600}
\end{figure}


\begin{figure}[h!]
	\centering
	\includegraphics[width=0.8\linewidth]{imgs/MLP 5 3600}
	\caption{Salida del MLP de 5 neuronas en capa oculta - \textit{dataset} de 3600 muestras}
	\label{fig:mlp-5-3600}
\end{figure}

\begin{figure}[h!]
	\centering
	\includegraphics[width=0.8\linewidth]{imgs/MLP 2 3600}
	\caption{Salida del MLP de 2 neuronas en capa oculta - \textit{dataset} de 3600 muestras}
	\label{fig:mlp-2-3600}
\end{figure}

\section{Apéndice 2 - Resultados de la segunda experiencia de identificación}
\label{ap2}

\begin{figure}[h!]
	\centering
	\includegraphics[width=0.8\linewidth]{imgs/prueba1_1}
	\caption{Comparación de salidas - prueba 1}
	\label{fig:prueba11}
\end{figure}
\begin{figure}[h!]
	\centering
	\includegraphics[width=0.8\linewidth]{imgs/prueba1_2}
	\caption{Comparación de salidas - prueba 1}
	\label{fig:prueba12}
\end{figure}

\begin{figure}[h!]
	\centering
	\includegraphics[width=0.8\linewidth]{imgs/prueba2_1}
	\caption{Comparación de salidas - prueba 2}
	\label{fig:prueba21}
\end{figure}
\begin{figure}[h!]
	\centering
	\includegraphics[width=0.8\linewidth]{imgs/prueba2_2}
	\caption{Comparación de salidas - prueba 2}
	\label{fig:prueba22}
\end{figure}

\begin{figure}[h!]
	\centering
	\includegraphics[width=0.8\linewidth]{imgs/prueba3_1}
	\caption{Comparación de salidas - prueba 3}
	\label{fig:prueba31}
\end{figure}
\begin{figure}[h!]
	\centering
	\includegraphics[width=0.8\linewidth]{imgs/prueba3_2}
	\caption{Comparación de salidas - prueba 3}
	\label{fig:prueba32}
\end{figure}

\begin{figure}[h!]
	\centering
	\includegraphics[width=0.8\linewidth]{imgs/prueba4_1}
	\caption{Comparación de salidas - prueba 4}
	\label{fig:prueba41}
\end{figure}
\begin{figure}[h!]
	\centering
	\includegraphics[width=0.8\linewidth]{imgs/prueba4_2}
	\caption{Comparación de salidas - prueba 4}
	\label{fig:prueba42}
\end{figure}

\begin{figure}[h!]
	\centering
	\includegraphics[width=0.8\linewidth]{imgs/prueba5_1}
	\caption{Comparación de salidas - prueba 5}
	\label{fig:prueba51}
\end{figure}
\begin{figure}[h!]
	\centering
	\includegraphics[width=0.8\linewidth]{imgs/prueba5_2}
	\caption{Comparación de salidas - prueba 5}
	\label{fig:prueba52}
\end{figure}



\end{document}



