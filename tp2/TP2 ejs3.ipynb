{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79d44e76",
   "metadata": {},
   "source": [
    "# Redes Neuronales - TP2\n",
    "## Ej 3\n",
    "\n",
    "Implemente un perceptrón multicapa que aprenda la función lógica XOR de 2 y de 4\n",
    "entradas (utilizando el algoritmo Backpropagation y actualizando en batch). Muestre\n",
    "cómo evoluciona el error durante el entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "815fd8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee833391",
   "metadata": {},
   "outputs": [],
   "source": [
    "class perceptron_simple:\n",
    "    def __init__(self):\n",
    "        self.pesos = None\n",
    "        self.lr = None\n",
    "        self.convergencia = False\n",
    "\n",
    "    def predict(self, x):\n",
    "        # x ya debe incluir el bias\n",
    "        return 1 if np.dot(self.pesos, x) >= 0 else -1 # función signo para predecir\n",
    "\n",
    "    def calcular_error(self, X, y):\n",
    "        \"\"\"calcula el error de clasificación en base a los pesos que tiene guardados, el X e Y. \"\"\"\n",
    "        error = 0\n",
    "        for xi, target in zip(X, y):\n",
    "            xi_con_bias = np.insert(xi, 0, 1) # agrega el 1 para la entrada de bias\n",
    "            prediccion = self.predict(xi_con_bias) # hace la predicción con los pesos actuales\n",
    "            if prediccion != target:\n",
    "                error += 1\n",
    "        return error\n",
    "\n",
    "    def train(self, X, y, epochs=100, lr=0.01):\n",
    "        \"\"\"\n",
    "        X: matriz de entradas (sin bias)\n",
    "        y: vector de salidas esperadas\n",
    "        epochs: cantidad de iteraciones sobre el dataset\n",
    "        lr: learning rate\n",
    "        \"\"\"\n",
    "        self.lr = lr\n",
    "        self.pesos = np.zeros(X.shape[1] + 1)  # tantos pesos como columnas en X más el bias\n",
    "        error_por_cambio = [] # vamos guardando el error por cada cambio de peso\n",
    "\n",
    "        # inicializo los pesos en valores aleatorios entre -1 y 1.\n",
    "        self.pesos = np.random.rand(X.shape[1] + 1)*2 -1 # tenemos valores de 0 a 2 y le resto 1 para tener negativos y positivos\n",
    "        \n",
    "        for _ in range(epochs):\n",
    "            for xi, target in zip(X, y):\n",
    "                xi_con_bias = np.insert(xi, 0, 1) # agrega el 1 para la entrada de bias\n",
    "                prediccion = self.predict(xi_con_bias) # hace la predicción con los pesos actuales\n",
    "                error = target - prediccion # calcula el error como la diferencia entre el valor esperado y el predicho\n",
    "                self.pesos += self.lr * error * xi_con_bias\n",
    "                error_luego_de_cambio = self.calcular_error(X,y)\n",
    "                error_por_cambio.append(error_luego_de_cambio) # guardo el error cada vez que cambia un peso\n",
    "                if error_luego_de_cambio < 0.01: # condición de corte: si no hay error, convergió\n",
    "                    break\n",
    "            if error_luego_de_cambio < 0.01: # condición de corte: si no hay error, convergió\n",
    "                self.convergencia = True\n",
    "                break\n",
    "        if self.convergencia == True:\n",
    "            return error_por_cambio\n",
    "        else:\n",
    "            return 0\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
