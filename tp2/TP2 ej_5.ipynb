{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79d44e76",
   "metadata": {
    "id": "79d44e76"
   },
   "source": [
    "# Redes Neuronales - TP2\n",
    "## Ej 5\n",
    "\n",
    "Siguiendo el trabajo de Hinton y Salakhutdinov (2006), entrene una máquina restringida\n",
    "de Boltzmann con imágenes de la base de datos MNIST. Muestre el error de\n",
    "recontruccion durante el entrenamiento, y ejemplos de cada uno de los dígitos\n",
    "reconstruidos.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b0b95d",
   "metadata": {},
   "source": [
    "La MRB se puede pensar como una red feedfoward de 4 capas, en vez de pensarla como una de 2 capas con pesos simétricos. $v$ es la capa visible y $h$ es la oculta, y tenemos un $\\hat{v}$ y $\\hat{h}$, que son las estimaciones. \n",
    "\n",
    "Las fórmulas que hay que seguir son las siguientes:\n",
    "\n",
    "$$\n",
    "m_i = \\text{pixel}_i\n",
    "$$\n",
    "\n",
    "$$\n",
    "v_i \\sim  \\mathcal{N}(m_i , 1)\n",
    "$$\n",
    "\n",
    "$$\n",
    "P_r (j) = g(\\sum _i w_{ij} v_i + b_j) \\quad \\quad g (x) = \\frac{1}{1+e^{-x}}\n",
    "$$\n",
    "\n",
    "$$\n",
    "h(j) = \n",
    "\\begin{cases}\n",
    "1 \\quad \\text{con probabilidad} \\quad P_r \n",
    "\\\\\n",
    "0 \\quad  \\text{con probabilidad}\\quad 1-P_r \n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{guardar} \\quad (v_i , h_j)_{data}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e778c1",
   "metadata": {},
   "source": [
    "Luego se repite pero para obtener las estimaciones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f56d151",
   "metadata": {},
   "source": [
    "$$\n",
    "m_i = \\sum _j w_{ij} v_i + b_i\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\hat{v}_i \\sim  \\mathcal{N}(m_i , 1)\n",
    "$$\n",
    "\n",
    "$$\n",
    "P_r (j) = g(\\sum _i w_{ij} v_i + b_j) \\quad \\quad g (x) = \\frac{1}{1+e^{-x}}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\hat{h}(j) = \n",
    "\\begin{cases}\n",
    "1 \\quad \\text{con probabilidad} \\quad P_r \n",
    "\\\\\n",
    "0 \\quad  \\text{con probabilidad}\\quad 1-P_r \n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{guardar} \\quad (v_i , h_j)_{reconstruccion}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5604ab05",
   "metadata": {},
   "source": [
    "Al final se hace\n",
    "\n",
    "$$\n",
    "\\Delta w_{ij}= \\eta ( \\left\\langle v_i h_j \\right\\rangle - \\left\\langle \\hat{v_i} \\hat{h_j} \\right\\rangle)\n",
    "$$\n",
    "\n",
    "$$\n",
    "b_i= \\eta ( \\left\\langle v_i \\right\\rangle - \\left\\langle \\hat{v_i} \\right\\rangle)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\Delta w_{ij}= \\eta ( \\left\\langle v_i h_j \\right\\rangle - \\left\\langle \\hat{v_i} \\hat{h_j} \\right\\rangle)\n",
    "$$\n",
    "$$\n",
    "b_j= \\eta ( \\left\\langle  h_j \\right\\rangle - \\left\\langle  \\hat{h_j} \\right\\rangle)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a63bb448",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae4c5441",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _sigmoid(x):\n",
    "    # Numéricamente estable: recortamos la entrada para evitar overflow en exp\n",
    "    x = np.asarray(x, dtype=np.float32)\n",
    "    x = np.clip(x, -50.0, 50.0)\n",
    "    return 1.0 / (1.0 + np.exp(-x))\n",
    "\n",
    "\n",
    "class RBM:\n",
    "  \"\"\"\n",
    "  RBM con visibles gaussianas (sigma=1) y ocultas binarias.\n",
    "\n",
    "  Pequeñas protecciones numéricas:\n",
    "    - recorte de entradas a la sigmoide para evitar overflow\n",
    "    - recorte de medias de visibles antes de muestrear\n",
    "  \"\"\"\n",
    "\n",
    "  def __init__(self, n_visible, n_hidden, lr=0.1, rng=None):\n",
    "      self.n_visible = int(n_visible)\n",
    "      self.n_hidden = int(n_hidden)\n",
    "      self.lr = float(lr)\n",
    "      self.rng = np.random.RandomState(None) if rng is None else rng\n",
    "\n",
    "      # pesos: forma (n_visible, n_hidden)\n",
    "      # inicialización pequeña\n",
    "      self.W = 0.01 * self.rng.randn(self.n_visible, self.n_hidden).astype(np.float32)\n",
    "      # sesgos visibles y ocultos\n",
    "      self.b = np.zeros(self.n_visible, dtype=np.float32)\n",
    "      self.c = np.zeros(self.n_hidden, dtype=np.float32)\n",
    "\n",
    "  def v_to_h(self, pixeles, sample=True, sample_visible=False):\n",
    "      \"\"\"Paso v -> h.\n",
    "      Args:\n",
    "        pixeles: array (batch, n_visible) con las medias m_i (por ejemplo los pixeles en [0,1])\n",
    "        sample: si True, devuelve muestras binarias de h además de las probabilidades\n",
    "        sample_visible: si True, primero muestrea visibles v ~ N(m,1); si False usa m directamente\n",
    "      Returns:\n",
    "        h_prob, h_samp\n",
    "      \"\"\"\n",
    "      m = np.asarray(pixeles, dtype=np.float32)  # media = pixel_i\n",
    "      if sample_visible:\n",
    "          # recortamos m para evitar medias absurdas antes de añadir ruido\n",
    "          m_clipped = np.clip(m, -10.0, 10.0)\n",
    "          v = m_clipped + self.rng.randn(*m.shape).astype(np.float32)\n",
    "      else:\n",
    "          v = m\n",
    "\n",
    "      pre = np.dot(v, self.W) + self.c\n",
    "      # evitar overflow numerico en la sigmoide\n",
    "      pre = np.clip(pre, -50.0, 50.0)\n",
    "      h_prob = _sigmoid(pre)\n",
    "      h_samp = None\n",
    "      if sample:\n",
    "          h_samp = (self.rng.rand(*h_prob.shape) < h_prob).astype(np.float32)\n",
    "      return h_prob, h_samp\n",
    "\n",
    "  def h_to_v(self, h, sample=True):\n",
    "      \"\"\"Paso h -> v.\n",
    "      Args:\n",
    "        h: array (batch, n_hidden) -- puede ser probabilidades o muestras\n",
    "        sample: si True, devuelve muestras gaussianas v ~ N(mean, 1); si False solo la media\n",
    "      Returns:\n",
    "        v_mean, v_samp\n",
    "      \"\"\"\n",
    "      h = np.asarray(h, dtype=np.float32)\n",
    "      v_mean = np.dot(h, self.W.T) + self.b\n",
    "      # recortamos v_mean para evitar que crezca descontroladamente\n",
    "      v_mean = np.clip(v_mean, -10.0, 10.0)\n",
    "      v_samp = None\n",
    "      if sample:\n",
    "          v_samp = v_mean + self.rng.randn(*v_mean.shape).astype(np.float32)\n",
    "      return v_mean, v_samp\n",
    "\n",
    "  def gradiente(self, v0, h0_prob, v1, h1_prob):\n",
    "      \"\"\"CD-1: calcula dW, db, dc usando probabilidades (h0_prob, h1_prob).\n",
    "      Args:\n",
    "        v0: batch de datos (N, n_visible)\n",
    "        h0_prob: P(h|v0) (N, n_hidden)\n",
    "        v1: reconstrucción de v (muestra) (N, n_visible)\n",
    "        h1_prob: P(h|v1) (N, n_hidden)\n",
    "      Returns:\n",
    "        dW, db, dc (ya multiplicados por lr)\n",
    "      \"\"\"\n",
    "      v0 = np.asarray(v0, dtype=np.float32)\n",
    "      v1 = np.asarray(v1, dtype=np.float32)\n",
    "      h0_prob = np.asarray(h0_prob, dtype=np.float32)\n",
    "      h1_prob = np.asarray(h1_prob, dtype=np.float32)\n",
    "\n",
    "      batch = float(v0.shape[0])\n",
    "      pos_assoc = np.dot(v0.T, h0_prob) / batch\n",
    "      neg_assoc = np.dot(v1.T, h1_prob) / batch\n",
    "\n",
    "      dW = self.lr * (pos_assoc - neg_assoc)\n",
    "      db = self.lr * (v0.mean(axis=0) - v1.mean(axis=0))\n",
    "      dc = self.lr * (h0_prob.mean(axis=0) - h1_prob.mean(axis=0))\n",
    "      return dW, db, dc\n",
    "\n",
    "  def reconstruct(self, v):\n",
    "      \"\"\"Reconstrucción determinística: v -> h_prob -> v_mean.\"\"\"\n",
    "      h_prob, _ = self.v_to_h(v, sample=False, sample_visible=False)\n",
    "      v_mean, _ = self.h_to_v(h_prob, sample=False)\n",
    "      return v_mean\n",
    "  \n",
    "\n",
    "  def train_loop(self, data, max_epochs=50, batch_size=64, tol=1e-4, verbose=True):\n",
    "          \"\"\"Superloop de entrenamiento que itera por épocas y batches.\n",
    "          Por defecto hace CD-1 usando:\n",
    "            - h0_prob = P(h|v0)\n",
    "            - h0_samp ~ Bernoulli(h0_prob)\n",
    "            - v1_samp ~ N(dot(h0_samp,W^T)+b, 1)\n",
    "            - h1_prob = P(h|v1_samp)\n",
    "          Y usa (v0, h0_prob) y (v1_samp, h1_prob) para calcular gradientes.\n",
    "          \"\"\"\n",
    "          X = np.asarray(data, dtype=np.float32)\n",
    "          N = X.shape[0]\n",
    "          # cubrir todo el dataset (incluyendo última fracción si N no es múltiplo de batch_size)\n",
    "          n_batches = int(np.ceil(float(N) / float(batch_size)))\n",
    "\n",
    "          epoch_errors = []\n",
    "          prev_epoch_err = None\n",
    "\n",
    "          for epoch in range(1, max_epochs + 1):\n",
    "              perm = self.rng.permutation(N)\n",
    "              epoch_err = 0.0\n",
    "              for b in range(n_batches):\n",
    "                  start = b * batch_size\n",
    "                  stop = min((b + 1) * batch_size, N)\n",
    "                  idx = perm[start:stop]\n",
    "                  if idx.size == 0:\n",
    "                      continue\n",
    "                  v0 = X[idx]\n",
    "\n",
    "                  # Paso 1: v -> h (obtener probabilidades y muestras)\n",
    "                  # Usamos sample=True para obtener muestras necesarias al cálculo del gradiente\n",
    "                  h0_prob, h0_samp = self.v_to_h(v0, sample=True, sample_visible=False)\n",
    "\n",
    "                  # Paso 2: h -> v (reconstrucción basada en la muestra) para la fase negativa del gradiente\n",
    "                  v1_mean_sample, v1_samp = self.h_to_v(h0_samp, sample=True)\n",
    "\n",
    "                  # Paso 3: v(recon) -> h (prob negative)\n",
    "                  h1_prob, _ = self.v_to_h(v1_samp, sample=False, sample_visible=False)\n",
    "\n",
    "                  # Paso 4: calcular gradientes usando probabilidades para las ocultas\n",
    "                  dW, db, dc = self.gradiente(v0, h0_prob, v1_samp, h1_prob)\n",
    "\n",
    "                  # Aplicar actualizaciones (opcional: clip de actualizaciones para prevenir explosión)\n",
    "                  self.W += dW\n",
    "                  self.b += db\n",
    "                  self.c += dc\n",
    "\n",
    "                  # ---- Medición del error para monitoreo: usar reconstrucción determinística ----\n",
    "                  # Esto evita comparar el MSE ruidoso (entrenamiento) contra el MSE determinístico (test).\n",
    "                  v1_mean_det, _ = self.h_to_v(h0_prob, sample=False)\n",
    "                  batch_err = np.mean((v0 - v1_mean_det) ** 2)\n",
    "                  epoch_err += batch_err\n",
    "\n",
    "              epoch_err /= float(n_batches)\n",
    "              epoch_errors.append(epoch_err)\n",
    "\n",
    "              if verbose:\n",
    "                  print(f\"Epoch {epoch:3d}/{max_epochs} - recon_error: {epoch_err:.6f}\")\n",
    "\n",
    "              # Criterio de convergencia: cambio pequeño en el error promedio por época\n",
    "              if prev_epoch_err is not None and abs(prev_epoch_err - epoch_err) < tol:\n",
    "                  if verbose:\n",
    "                      print(\"Converged (tol reached). Stopping training.\")\n",
    "                  break\n",
    "              prev_epoch_err = epoch_err\n",
    "\n",
    "          return epoch_errors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d07c166e",
   "metadata": {},
   "source": [
    "## Entrenamiento con MNIST\n",
    "\n",
    "En estas celdas cargamos MNIST, preprocesamos las imágenes (normalización y aplanado),\n",
    "entrenamos la RBM usando `train_loop` implementado más arriba y luego mostramos\n",
    "el error de reconstrucción por época y algunas reconstrucciones de ejemplo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9a1b0ad",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Traceback (most recent call last):\n  File \"c:\\Users\\q\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 73, in <module>\n    from tensorflow.python._pywrap_tensorflow_internal import *\nImportError: DLL load failed while importing _pywrap_tensorflow_internal: Error en una rutina de inicialización de biblioteca de vínculos dinámicos (DLL).\n\n\nFailed to load the native TensorFlow runtime.\nSee https://www.tensorflow.org/install/errors for some common causes and solutions.\nIf you need help, create an issue at https://github.com/tensorflow/tensorflow/issues and include the entire stack trace above this error message.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\q\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py:73\u001b[39m\n\u001b[32m     72\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m   \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_pywrap_tensorflow_internal\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *\n\u001b[32m     74\u001b[39m \u001b[38;5;66;03m# This try catch logic is because there is no bazel equivalent for py_extension.\u001b[39;00m\n\u001b[32m     75\u001b[39m \u001b[38;5;66;03m# Externally in opensource we must enable exceptions to load the shared object\u001b[39;00m\n\u001b[32m     76\u001b[39m \u001b[38;5;66;03m# by exposing the PyInit symbols with pybind. This error will only be\u001b[39;00m\n\u001b[32m     77\u001b[39m \u001b[38;5;66;03m# caught internally or if someone changes the name of the target _pywrap_tensorflow_internal.\u001b[39;00m\n\u001b[32m     78\u001b[39m \n\u001b[32m     79\u001b[39m \u001b[38;5;66;03m# This logic is used in other internal projects using py_extension.\u001b[39;00m\n",
      "\u001b[31mImportError\u001b[39m: DLL load failed while importing _pywrap_tensorflow_internal: Error en una rutina de inicialización de biblioteca de vínculos dinámicos (DLL).",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Preparar MNIST y entrenar la RBM\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdatasets\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m mnist\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Cargar MNIST\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\q\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\__init__.py:2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# DO NOT EDIT. Generated by api_gen.sh\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DTypePolicy\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FloatDTypePolicy\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Function\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\q\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\api\\__init__.py:8\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[33;03m\"\"\"DO NOT EDIT.\u001b[39;00m\n\u001b[32m      2\u001b[39m \n\u001b[32m      3\u001b[39m \u001b[33;03mThis file was autogenerated. Do not edit it by hand,\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[33;03msince your modifications would be overwritten.\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m activations\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m applications\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m backend\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\q\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\api\\activations\\__init__.py:7\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[33;03m\"\"\"DO NOT EDIT.\u001b[39;00m\n\u001b[32m      2\u001b[39m \n\u001b[32m      3\u001b[39m \u001b[33;03mThis file was autogenerated. Do not edit it by hand,\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[33;03msince your modifications would be overwritten.\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mactivations\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m deserialize\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mactivations\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mactivations\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m serialize\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\q\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\__init__.py:1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msrc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m activations\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msrc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m applications\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msrc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m backend\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\q\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\activations\\__init__.py:3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtypes\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mactivations\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mactivations\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m celu\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mactivations\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mactivations\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m elu\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mactivations\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mactivations\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m exponential\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\q\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\activations\\activations.py:1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msrc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m backend\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msrc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ops\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mapi_export\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m keras_export\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\q\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend\\__init__.py:10\u001b[39m\n\u001b[32m      7\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mapi_export\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m keras_export\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbackend\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcommon\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdtypes\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m result_type\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbackend\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcommon\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkeras_tensor\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m KerasTensor\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbackend\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcommon\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkeras_tensor\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m any_symbolic_tensors\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\q\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend\\common\\__init__.py:2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbackend\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcommon\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m backend_utils\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbackend\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcommon\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdtypes\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m result_type\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbackend\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcommon\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mvariables\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AutocastScope\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbackend\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcommon\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mvariables\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Variable \u001b[38;5;28;01mas\u001b[39;00m KerasVariable\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\q\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend\\common\\dtypes.py:5\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mapi_export\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m keras_export\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbackend\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m config\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbackend\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcommon\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mvariables\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m standardize_dtype\n\u001b[32m      7\u001b[39m BOOL_TYPES = (\u001b[33m\"\u001b[39m\u001b[33mbool\u001b[39m\u001b[33m\"\u001b[39m,)\n\u001b[32m      8\u001b[39m INT_TYPES = (\n\u001b[32m      9\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33muint8\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     10\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33muint16\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     16\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mint64\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     17\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\q\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend\\common\\variables.py:11\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbackend\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcommon\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mstateless_scope\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_stateless_scope\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbackend\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcommon\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mstateless_scope\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m in_stateless_scope\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodule_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tensorflow \u001b[38;5;28;01mas\u001b[39;00m tf\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnaming\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m auto_name\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mVariable\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\q\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\__init__.py:1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01maudio_dataset_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m audio_dataset_from_directory\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdataset_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m split_dataset\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfile_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_file\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\q\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\audio_dataset_utils.py:4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mapi_export\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m keras_export\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m dataset_utils\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodule_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tensorflow \u001b[38;5;28;01mas\u001b[39;00m tf\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodule_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tensorflow_io \u001b[38;5;28;01mas\u001b[39;00m tfio\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\q\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\dataset_utils.py:9\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmultiprocessing\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpool\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ThreadPool\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msrc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tree\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mapi_export\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m keras_export\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m io_utils\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\q\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\tree\\__init__.py:1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtree\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtree_api\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m assert_same_paths\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtree\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtree_api\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m assert_same_structure\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtree\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtree_api\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m flatten\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\q\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\tree\\tree_api.py:8\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodule_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m optree\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m optree.available:\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtree\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m optree_impl \u001b[38;5;28;01mas\u001b[39;00m tree_impl\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m dmtree.available:\n\u001b[32m     10\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtree\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m dmtree_impl \u001b[38;5;28;01mas\u001b[39;00m tree_impl\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\q\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\tree\\optree_impl.py:13\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# Register backend-specific node classes\u001b[39;00m\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m backend() == \u001b[33m\"\u001b[39m\u001b[33mtensorflow\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtrackable\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata_structures\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ListWrapper\n\u001b[32m     14\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtrackable\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata_structures\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _DictWrapper\n\u001b[32m     16\u001b[39m     optree.register_pytree_node(\n\u001b[32m     17\u001b[39m         ListWrapper,\n\u001b[32m     18\u001b[39m         \u001b[38;5;28;01mlambda\u001b[39;00m x: (x, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[32m     19\u001b[39m         \u001b[38;5;28;01mlambda\u001b[39;00m metadata, children: ListWrapper(\u001b[38;5;28mlist\u001b[39m(children)),\n\u001b[32m     20\u001b[39m         namespace=\u001b[33m\"\u001b[39m\u001b[33mkeras\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     21\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\q\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\__init__.py:40\u001b[39m\n\u001b[32m     37\u001b[39m _os.environ.setdefault(\u001b[33m\"\u001b[39m\u001b[33mENABLE_RUNTIME_UPTIME_TELEMETRY\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m1\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     39\u001b[39m \u001b[38;5;66;03m# Do not remove this line; See https://github.com/tensorflow/tensorflow/issues/42596\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m pywrap_tensorflow \u001b[38;5;28;01mas\u001b[39;00m _pywrap_tensorflow  \u001b[38;5;66;03m# pylint: disable=unused-import\u001b[39;00m\n\u001b[32m     41\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtools\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m module_util \u001b[38;5;28;01mas\u001b[39;00m _module_util\n\u001b[32m     42\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutil\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlazy_loader\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m KerasLazyLoader \u001b[38;5;28;01mas\u001b[39;00m _KerasLazyLoader\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\q\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py:88\u001b[39m\n\u001b[32m     86\u001b[39m     sys.setdlopenflags(_default_dlopen_flags)\n\u001b[32m     87\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m88\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[32m     89\u001b[39m       \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtraceback.format_exc()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\n\u001b[32m     90\u001b[39m       \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mFailed to load the native TensorFlow runtime.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m'\u001b[39m\n\u001b[32m     91\u001b[39m       \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mSee https://www.tensorflow.org/install/errors \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     92\u001b[39m       \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mfor some common causes and solutions.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m'\u001b[39m\n\u001b[32m     93\u001b[39m       \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mIf you need help, create an issue \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     94\u001b[39m       \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mat https://github.com/tensorflow/tensorflow/issues \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     95\u001b[39m       \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mand include the entire stack trace above this error message.\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     97\u001b[39m \u001b[38;5;66;03m# pylint: enable=wildcard-import,g-import-not-at-top,unused-import,line-too-long\u001b[39;00m\n",
      "\u001b[31mImportError\u001b[39m: Traceback (most recent call last):\n  File \"c:\\Users\\q\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 73, in <module>\n    from tensorflow.python._pywrap_tensorflow_internal import *\nImportError: DLL load failed while importing _pywrap_tensorflow_internal: Error en una rutina de inicialización de biblioteca de vínculos dinámicos (DLL).\n\n\nFailed to load the native TensorFlow runtime.\nSee https://www.tensorflow.org/install/errors for some common causes and solutions.\nIf you need help, create an issue at https://github.com/tensorflow/tensorflow/issues and include the entire stack trace above this error message."
     ]
    }
   ],
   "source": [
    "# Preparar MNIST y entrenar la RBM\n",
    "from keras.datasets import mnist\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Cargar MNIST\n",
    "(train_X, train_y), (test_X, test_y) = mnist.load_data()\n",
    "\n",
    "# Preprocesamiento:\n",
    "# - aplanar\n",
    "# - normalizar: dejamos los pixeles en rango [0,1] y usamos la interpretación de visibles gaussianas\n",
    "#   con media igual al pixel (m_i = pixel_i). Para respetar eso, simplemente usamos los valores\n",
    "#   en [0,1] como medias cuando alimentamos v_to_h en la clase.\n",
    "\n",
    "train_X = train_X.astype(np.float32) / 255.0\n",
    "test_X = test_X.astype(np.float32) / 255.0\n",
    "\n",
    "X = train_X.reshape(-1, 28 * 28)\n",
    "\n",
    "# Instanciar RBM\n",
    "#rbm = RBM(28 * 28, 256, lr=0.01)\n",
    "\n",
    "# Entrenar\n",
    "#errs = rbm.train_loop(X, max_epochs=25, batch_size=128, tol=1e-5, verbose=True)\n",
    "\n",
    "# Guardar errores y modelo en memoria\n",
    "#train_errors = errs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab8d244",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_recon_and_error(rbm, X, train_errors, n_show=10, title_prefix=None, test_mse=None):\n",
    "    \"\"\"Muestra la curva de error por época y una rejilla de `n_show` originales vs reconstrucciones.\n",
    "\n",
    "    Args:\n",
    "      rbm: instancia entrenada de RBM\n",
    "      X: matriz (N, n_visible) usada para obtener los `n_show` primeros ejemplos para visualizar\n",
    "      train_errors: lista de floats con el error por época\n",
    "      n_show: cuántas imágenes mostrar\n",
    "      title_prefix: texto opcional para anteponer al título (p. ej. clave del experimento)\n",
    "      test_mse: (opcional) valor escalar de MSE sobre el set de prueba para mostrar en el plot\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "\n",
    "    # Plot error (training)\n",
    "    plt.figure(figsize=(6,4))\n",
    "    plt.plot(train_errors, '-o')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Recon Error (MSE)')\n",
    "    title = 'Recon Error por Época (train)'\n",
    "    if title_prefix:\n",
    "        title = f\"{title_prefix} - {title}\"\n",
    "    if test_mse is not None:\n",
    "        # mostrar test MSE en el título y en consola\n",
    "        title = f\"{title} | test MSE: {test_mse:.6f}\"\n",
    "        print(f\"Test MSE: {test_mse:.6f}\")\n",
    "    plt.title(title)\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    # Mostrar algunas reconstrucciones (primeras n_show del conjunto X)\n",
    "    n_show = int(n_show)\n",
    "    orig = np.asarray(X, dtype=np.float32)[:n_show]\n",
    "    recons = rbm.reconstruct(orig)\n",
    "\n",
    "    # Clip para visualizar mejor en [0,1]\n",
    "    recons = np.clip(recons, 0.0, 1.0)\n",
    "    orig_disp = np.clip(orig, 0.0, 1.0)\n",
    "\n",
    "    plt.figure(figsize=(n_show * 2, 4))\n",
    "    for i in range(n_show):\n",
    "        ax = plt.subplot(2, n_show, i + 1)\n",
    "        plt.imshow(orig_disp[i].reshape(28,28), cmap='gray')\n",
    "        plt.axis('off')\n",
    "        if i == 0:\n",
    "            ax.set_title('Originals')\n",
    "\n",
    "        ax = plt.subplot(2, n_show, n_show + i + 1)\n",
    "        plt.imshow(recons[i].reshape(28,28), cmap='gray')\n",
    "        plt.axis('off')\n",
    "        if i == 0:\n",
    "            ax.set_title('Reconstructions')\n",
    "    # repetir título para la figura de reconstrucciones\n",
    "    plt.suptitle(title)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af85bc4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Training h400_e100 ---\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'RBM' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      9\u001b[39m key = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mh\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_hidden\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_e\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m--- Training \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m ---\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m rbm = \u001b[43mRBM\u001b[49m(\u001b[32m28\u001b[39m * \u001b[32m28\u001b[39m, n_hidden, lr=\u001b[32m0.01\u001b[39m)\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# entrenar sin imprimir cada epoch para evitar duplicados\u001b[39;00m\n\u001b[32m     13\u001b[39m errs = rbm.train_loop(X, max_epochs=epochs, batch_size=\u001b[32m128\u001b[39m, tol=\u001b[32m1e-5\u001b[39m, verbose=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[31mNameError\u001b[39m: name 'RBM' is not defined"
     ]
    }
   ],
   "source": [
    "# Experimentos: entrenar 9 modelos (3 tamaños ocultos x 3 números de épocas)\n",
    "hidden_sizes = [400, 200, 100]\n",
    "epochs_list = [100]\n",
    "results = {}\n",
    "n_show = 10\n",
    "\n",
    "for n_hidden in hidden_sizes:\n",
    "    for epochs in epochs_list:\n",
    "        key = f\"h{n_hidden}_e{epochs}\"\n",
    "        print(f\"--- Training {key} ---\")\n",
    "        rbm = RBM(28 * 28, n_hidden, lr=0.01)\n",
    "        # entrenar sin imprimir cada epoch para evitar duplicados\n",
    "        errs = rbm.train_loop(X, max_epochs=epochs, batch_size=128, tol=1e-5, verbose=False)\n",
    "        # MSE final en entrenamiento (último valor registrado)\n",
    "        train_final_mse = float(errs[-1]) if len(errs) > 0 else float('nan')\n",
    "\n",
    "        # evaluar reconstrucción en el set de prueba usando MSE (determinístico) UNA VEZ\n",
    "        test_subset = np.asarray(test_X.reshape(-1, 28*28), dtype=np.float32)\n",
    "        recon_test = rbm.reconstruct(test_subset)\n",
    "        test_mse = float(np.mean((test_subset - recon_test) ** 2))\n",
    "\n",
    "        results[key] = {'errors': [float(e) for e in errs], 'train_final_mse': train_final_mse, 'test_mse': test_mse}\n",
    "        # imprimir un resumen único por experimento\n",
    "        print(f\"Finished {key} | train_final_mse={train_final_mse:.6f} | test_mse={test_mse:.6f}\")\n",
    "\n",
    "        # mostrar curvas y reconstrucciones sobre el set de prueba (opcional visual)\n",
    "        show_recon_and_error(rbm, test_subset, errs, n_show=n_show, title_prefix=key, test_mse=test_mse)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
